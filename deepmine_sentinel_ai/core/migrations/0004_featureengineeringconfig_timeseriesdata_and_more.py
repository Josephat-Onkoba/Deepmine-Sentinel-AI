# Generated by Django 5.2.4 on 2025-07-14 12:28

import datetime
import django.core.validators
import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('core', '0003_alter_impactfactor_mine_site'),
    ]

    operations = [
        migrations.CreateModel(
            name='FeatureEngineeringConfig',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('config_name', models.CharField(help_text='Unique name for this feature configuration', max_length=100, unique=True)),
                ('version', models.CharField(default='1.0', help_text='Version of this configuration', max_length=20)),
                ('description', models.TextField(help_text='Description of feature engineering approach')),
                ('enabled_sensor_types', models.JSONField(help_text='List of sensor types to include')),
                ('enabled_feature_types', models.JSONField(help_text='List of feature types to generate')),
                ('window_sizes', models.JSONField(default=list, help_text='List of time window sizes for aggregation (in hours)')),
                ('aggregation_functions', models.JSONField(default=list, help_text='List of aggregation functions to apply')),
                ('include_fft_features', models.BooleanField(default=False, help_text='Include FFT-based frequency features')),
                ('fft_frequency_bands', models.JSONField(blank=True, default=list, help_text='Frequency bands for FFT analysis')),
                ('include_event_features', models.BooleanField(default=True, help_text='Include operational event-based features')),
                ('event_decay_factor', models.FloatField(default=0.95, help_text='Decay factor for event impact over time', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('normalization_method', models.CharField(choices=[('minmax', 'Min-Max Scaling'), ('zscore', 'Z-Score Normalization'), ('robust', 'Robust Scaling'), ('quantile', 'Quantile Normalization')], default='zscore', help_text='Method for feature normalization', max_length=20)),
                ('outlier_detection_method', models.CharField(choices=[('iqr', 'Interquartile Range'), ('zscore', 'Z-Score Method'), ('isolation_forest', 'Isolation Forest'), ('none', 'No Outlier Detection')], default='iqr', help_text='Method for outlier detection', max_length=20)),
                ('outlier_threshold', models.FloatField(default=3.0, help_text='Threshold for outlier detection', validators=[django.core.validators.MinValueValidator(0)])),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('is_active', models.BooleanField(default=True, help_text='Whether this configuration is active')),
            ],
            options={
                'verbose_name': 'Feature Engineering Configuration',
                'verbose_name_plural': 'Feature Engineering Configurations',
                'ordering': ['-created_at'],
                'unique_together': {('config_name', 'version')},
            },
        ),
        migrations.CreateModel(
            name='TimeSeriesData',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('sequence_id', models.CharField(help_text='Unique identifier for this time series sequence', max_length=100)),
                ('sequence_type', models.CharField(choices=[('training', 'Training Sequence'), ('validation', 'Validation Sequence'), ('test', 'Test Sequence'), ('prediction', 'Live Prediction Input')], default='training', help_text='Type of sequence for ML pipeline', max_length=20)),
                ('start_timestamp', models.DateTimeField(help_text='Start time of the sequence')),
                ('end_timestamp', models.DateTimeField(help_text='End time of the sequence')),
                ('sequence_length', models.IntegerField(help_text='Number of time steps in sequence', validators=[django.core.validators.MinValueValidator(1)])),
                ('sampling_interval', models.DurationField(default=datetime.timedelta(seconds=3600), help_text='Time interval between samples')),
                ('feature_set', models.CharField(choices=[('basic', 'Basic Features (sensor data only)'), ('enhanced', 'Enhanced Features (sensor + operational)'), ('engineered', 'Engineered Features (with derived metrics)'), ('full', 'Full Feature Set (all available features)')], default='enhanced', help_text='Set of features included in this sequence', max_length=20)),
                ('feature_count', models.IntegerField(help_text='Number of features per time step', validators=[django.core.validators.MinValueValidator(1)])),
                ('raw_features', models.JSONField(help_text='Raw feature values [timesteps, features]')),
                ('normalized_features', models.JSONField(help_text='Normalized feature values for ML training')),
                ('feature_names', models.JSONField(help_text='List of feature names in order')),
                ('impact_score_sequence', models.JSONField(help_text='Sequence of impact scores (target values)')),
                ('risk_level_sequence', models.JSONField(help_text='Sequence of risk levels (categorical targets)')),
                ('future_impact_scores', models.JSONField(blank=True, help_text='Future impact scores for prediction horizons', null=True)),
                ('data_quality_score', models.FloatField(default=1.0, help_text='Overall data quality score (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('missing_data_percentage', models.FloatField(default=0.0, help_text='Percentage of missing data points', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(100)])),
                ('anomaly_count', models.IntegerField(default=0, help_text='Number of anomalous data points detected', validators=[django.core.validators.MinValueValidator(0)])),
                ('preprocessing_version', models.CharField(default='1.0', help_text='Version of preprocessing pipeline used', max_length=20)),
                ('processing_timestamp', models.DateTimeField(auto_now_add=True, help_text='When this sequence was processed')),
                ('is_valid', models.BooleanField(default=True, help_text='Whether sequence passes validation checks')),
                ('validation_errors', models.JSONField(blank=True, default=list, help_text='List of validation errors if any')),
                ('sequence_overlap', models.FloatField(default=0.5, help_text='Overlap with adjacent sequences (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('is_augmented', models.BooleanField(default=False, help_text='Whether this sequence is from data augmentation')),
                ('augmentation_type', models.CharField(blank=True, help_text='Type of augmentation applied', max_length=50)),
                ('stope', models.ForeignKey(help_text='Associated stope', on_delete=django.db.models.deletion.CASCADE, related_name='time_series_data', to='core.stope')),
            ],
            options={
                'verbose_name': 'Time Series Data',
                'verbose_name_plural': 'Time Series Data',
                'ordering': ['-processing_timestamp'],
            },
        ),
        migrations.CreateModel(
            name='DataQualityMetrics',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('completeness_score', models.FloatField(help_text='Data completeness score (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('missing_sensor_types', models.JSONField(default=list, help_text='List of sensor types with missing data')),
                ('missing_data_gaps', models.JSONField(default=list, help_text='List of time gaps with missing data')),
                ('consistency_score', models.FloatField(help_text='Data consistency score (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('outlier_count', models.IntegerField(default=0, help_text='Number of outlier data points', validators=[django.core.validators.MinValueValidator(0)])),
                ('outlier_percentage', models.FloatField(default=0.0, help_text='Percentage of outlier data points', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(100)])),
                ('validity_score', models.FloatField(help_text='Data validity score (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('invalid_readings_count', models.IntegerField(default=0, help_text='Number of invalid sensor readings', validators=[django.core.validators.MinValueValidator(0)])),
                ('sensor_failure_events', models.JSONField(default=list, help_text='List of detected sensor failure events')),
                ('temporal_resolution_score', models.FloatField(help_text='Quality of temporal resolution (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('timestamp_irregularities', models.IntegerField(default=0, help_text='Number of timestamp irregularities', validators=[django.core.validators.MinValueValidator(0)])),
                ('overall_quality_score', models.FloatField(help_text='Overall data quality score (0.0-1.0)', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(1)])),
                ('quality_grade', models.CharField(choices=[('A', 'Excellent (>0.9)'), ('B', 'Good (0.8-0.9)'), ('C', 'Fair (0.7-0.8)'), ('D', 'Poor (0.6-0.7)'), ('F', 'Failing (<0.6)')], help_text='Letter grade for data quality', max_length=2)),
                ('analysis_timestamp', models.DateTimeField(auto_now_add=True)),
                ('analysis_version', models.CharField(default='1.0', help_text='Version of quality analysis algorithm', max_length=20)),
                ('time_series_data', models.OneToOneField(on_delete=django.db.models.deletion.CASCADE, related_name='quality_metrics', to='core.timeseriesdata')),
            ],
            options={
                'verbose_name': 'Data Quality Metrics',
                'verbose_name_plural': 'Data Quality Metrics',
            },
        ),
        migrations.AddIndex(
            model_name='timeseriesdata',
            index=models.Index(fields=['stope', 'start_timestamp'], name='core_timese_stope_i_0c44c8_idx'),
        ),
        migrations.AddIndex(
            model_name='timeseriesdata',
            index=models.Index(fields=['sequence_type', 'is_valid'], name='core_timese_sequenc_297c55_idx'),
        ),
        migrations.AddIndex(
            model_name='timeseriesdata',
            index=models.Index(fields=['feature_set', 'preprocessing_version'], name='core_timese_feature_902270_idx'),
        ),
        migrations.AddIndex(
            model_name='timeseriesdata',
            index=models.Index(fields=['data_quality_score'], name='core_timese_data_qu_5cd06e_idx'),
        ),
        migrations.AddIndex(
            model_name='timeseriesdata',
            index=models.Index(fields=['processing_timestamp'], name='core_timese_process_400127_idx'),
        ),
        migrations.AlterUniqueTogether(
            name='timeseriesdata',
            unique_together={('stope', 'sequence_id')},
        ),
    ]
